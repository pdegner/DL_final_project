{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the first page in this topic\n",
    "\n",
    "### Sorting out what I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexes_url = \"https://www.mountainproject.com/forum/topic/118978980/recommendations-on-hexes\"\n",
    "uClient = uReq(hexes_url) # request the URL\n",
    "page_html = uClient.read() # Read the html\n",
    "uClient.close() # close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recommendations on hexes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hexes_soup = soup(page_html, \"html.parser\") # get soup of the webpage\n",
    "hexes_soup.h1.text # topic name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_container = hexes_soup.findAll(\"div\", {\"class\":\"fr-view\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"fr-view\">\n",
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\n",
       "\n",
       "<?xml encoding='utf-8' ?><html><body><div><a href=\"https://cdn2.apstatic.com/forum/168709.jpg\" rel=\"nofollow noopener noreferrer\" target=\"_blank\"><img class=\"img-fluid lazy forum-img\" data-original=\"https://cdn2.apstatic.com/forum/168709.jpg\"/></a></div></body></html>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_container[8] # no text in this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"fr-view\">\n",
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\n",
       "\n",
       "<?xml encoding='utf-8' ?><html><body><p>Hello all, I'm trying to get into trad climbing but I'm also a starving college student. As I understand, hexes are a lightweight and cost-effective alternative to getting cams. Any recommendations on which ones are the best to get? Or should I just say screw it and purchase cams? Thanks!</p></body></html>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_container[0] # text of posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'May 2020'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_container = hexes_soup.findAll(\"div\", {\"class\":\"bio text-truncate\"})\n",
    "bio_container[0].div.find_next('span').find_next('span').text.split(\"Joined \")[1].split(\"\\n\")[0] # date joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jun 3, 2020'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_container[0].div.find_next('a').find_next('a').strong.text # date posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_container = hexes_soup.findAll(\"span\", {\"class\":\"num-likes text-muted\"})\n",
    "int(likes_container[0].text) # number of likes on the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bio_container[13].div.find_next('a').find_next('a').strong.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is only a concern for your first piece of pro on each pitch and is easily mitigated:  place a cam for your first piece or use one of the bolts if its a bolted anchor or use the highest and/or best cam in your anchor.  I agree. Op spoke of using only nuts on a trad climb. I will add: “...highest and/or best cam in your anchor” on a multi pitch. \n"
     ]
    }
   ],
   "source": [
    "mess_text = \"\"\n",
    "for i in range(len(message_container[13].findAll('p'))):\n",
    "    mess_text += message_container[13].findAll('p')[i].text\n",
    "\n",
    "print(mess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HTML info\n",
    "hexes_url = \"https://www.mountainproject.com/forum/topic/118978980/recommendations-on-hexes\"\n",
    "uClient = uReq(hexes_url) # request the URL\n",
    "page_html = uClient.read() # Read the html\n",
    "uClient.close() # close the connection\n",
    "\n",
    "# Get soup and containers\n",
    "hexes_soup = soup(page_html, \"html.parser\")\n",
    "message_container = hexes_soup.findAll(\"div\", {\"class\":\"fr-view\"})\n",
    "bio_container = hexes_soup.findAll(\"div\", {\"class\":\"bio text-truncate\"})\n",
    "likes_container = hexes_soup.findAll(\"span\", {\"class\":\"num-likes text-muted\"})\n",
    "\n",
    "# Open a new file\n",
    "filename = \"hexes.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# loop to get everything\n",
    "for i in range(len(message_container)):\n",
    "    topic = hexes_soup.h1.text\n",
    "    try:\n",
    "        mess_text = \"\"\n",
    "        for j in range(len(message_container[i].findAll('p'))):\n",
    "            mess_text += \" \" + message_container[i].findAll('p')[j].text\n",
    "    except:\n",
    "        mess_text = str(message_container[i].p) # outputs string \"None\" if image only\n",
    "    join_date = bio_container[i].div.find_next('span').find_next('span').text.split(\"Joined \")[1].split(\"\\n\")[0]\n",
    "    post_date = bio_container[i].div.find_next('a').find_next('a').strong.text\n",
    "    num_likes = str(int(likes_container[i].text))\n",
    "    \n",
    "    f.write(topic +\",\"+ \n",
    "            mess_text.replace(\",\", \"~\") +\",\"+ \n",
    "            join_date +\",\"+ \n",
    "            post_date.replace(\",\",\"\") +\",\"+ \n",
    "            num_likes + \"\\n\")\n",
    "    \n",
    "f.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping all the pages in this topic\n",
    "\n",
    "### Sorting out what I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pages_container = hexes_soup.findAll(\"a\", {\"class\":\"no-click\"})\n",
    "num_pages = int(num_pages_container[2].text.split(\"of \")[1].split(\"\\n\")[0])\n",
    "num_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a new file\n",
    "filename = \"hexes.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "\n",
    "# Get list of URLs from topic\n",
    "hexes_url = \"https://www.mountainproject.com/forum/topic/118978980/recommendations-on-hexes\"\n",
    "url_list = []\n",
    "for i in range(1, num_pages+1):\n",
    "    if i == 1:\n",
    "        url = hexes_url\n",
    "    else: \n",
    "        url = hexes_url + \"?page=\" + str(i)\n",
    "    url_list.append(url)\n",
    "\n",
    "\n",
    "for url in url_list:\n",
    "\n",
    "    # Get HTML info\n",
    "    hexes_url = url\n",
    "    uClient = uReq(hexes_url) # request the URL\n",
    "    page_html = uClient.read() # Read the html\n",
    "    uClient.close() # close the connection\n",
    "\n",
    "    # Get soup and containers\n",
    "    hexes_soup = soup(page_html, \"html.parser\")\n",
    "    message_container = hexes_soup.findAll(\"div\", {\"class\":\"fr-view\"})\n",
    "    bio_container = hexes_soup.findAll(\"div\", {\"class\":\"bio text-truncate\"})\n",
    "    likes_container = hexes_soup.findAll(\"span\", {\"class\":\"num-likes text-muted\"})\n",
    "\n",
    "\n",
    "    # loop to get everything\n",
    "    for i in range(len(message_container)):\n",
    "        topic = hexes_soup.h1.text\n",
    "        page_num = url[-1]\n",
    "        post_num = str(i)\n",
    "        try:\n",
    "            mess_text = \"\"\n",
    "            for j in range(len(message_container[i].findAll('p'))):\n",
    "                mess_text += \" \" + message_container[i].findAll('p')[j].text\n",
    "        except:\n",
    "            mess_text = str(message_container[i].p) # outputs empty string if image only\n",
    "        join_date = bio_container[i].div.find_next('span').find_next('span').text.split(\"Joined \")[1].split(\"\\n\")[0]\n",
    "        post_date = bio_container[i].div.find_next('a').find_next('a').strong.text\n",
    "        num_likes = str(int(likes_container[i].text))\n",
    "\n",
    "        f.write(topic +\",\"+ \n",
    "                page_num +\",\"+\n",
    "                post_num +\",\"+\n",
    "                mess_text.replace(\",\", \"~\") +\",\"+ \n",
    "                join_date +\",\"+ \n",
    "                post_date.replace(\",\",\"\") +\",\"+ \n",
    "                num_likes + \"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping all the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forum_scrape(url_to_scrape):\n",
    "    \"\"\"Get all data from a given forum url\"\"\"\n",
    "    \n",
    "    # Get HTML info\n",
    "    uClient = uReq(url_to_scrape) # request the URL\n",
    "    page_html = uClient.read() # Read the html\n",
    "    uClient.close() # close the connection\n",
    "    \n",
    "    # How many pages long is this forum topic?\n",
    "    forum_soup = soup(page_html, \"html.parser\")\n",
    "    num_pages_container = forum_soup.findAll(\"a\", {\"class\":\"no-click\"})\n",
    "    try:\n",
    "        num_pages = int(num_pages_container[2].text.split(\"of \")[1].split(\"\\n\")[0])\n",
    "    except:\n",
    "        num_pages = 1\n",
    "\n",
    "    # loop over each page\n",
    "    url_list = []\n",
    "    for page in range(1, num_pages+1):\n",
    "        if page == 1:\n",
    "            new_url = url_to_scrape\n",
    "        else: \n",
    "            new_url = url_to_scrape + \"?page=\" + str(page)\n",
    "        url_list.append(new_url)\n",
    "    \n",
    "    for url in url_list:\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Get HTML info\n",
    "        uClient = uReq(url) # request the URL\n",
    "        page_html = uClient.read() # Read the html\n",
    "        uClient.close() # close the connection\n",
    "\n",
    "        # Get soup and containers\n",
    "        forum_soup = soup(page_html, \"html.parser\")\n",
    "        message_container = forum_soup.findAll(\"div\", {\"class\":\"fr-view\"})\n",
    "        bio_container = forum_soup.findAll(\"div\", {\"class\":\"bio text-truncate\"})\n",
    "        likes_container = forum_soup.findAll(\"span\", {\"class\":\"num-likes text-muted\"})\n",
    "    \n",
    "        # get everything on the page\n",
    "        for m in range(len(message_container)):\n",
    "            \n",
    "            topic = forum_soup.h1.text\n",
    "            page_num = url[-1]\n",
    "            post_num = str(m)\n",
    "            try:\n",
    "                mess_text = \"\"\n",
    "                for j in range(len(message_container[m].findAll('p'))):\n",
    "                    mess_text += \" \" + message_container[m].findAll('p')[j].text\n",
    "            except:\n",
    "                mess_text = str(message_container[m].p) # outputs empty string if image only\n",
    "            \n",
    "            join_date = bio_container[m].div.find_next('span').find_next('span').text.split(\"Joined \")[1].split(\"\\n\")[0]\n",
    "            post_date = bio_container[m].div.find_next('a').find_next('a').strong.text\n",
    "            if len(likes_container) == len(message_container):\n",
    "                num_likes = str(int(likes_container[m].text))\n",
    "            else:\n",
    "                num_likes = str(10000)\n",
    "            \n",
    "\n",
    "            f.write(topic.replace(\",\", \"~\") +\",\"+ \n",
    "                    page_num +\",\"+\n",
    "                    post_num +\",\"+\n",
    "                    mess_text.replace(\",\", \"~\") +\",\"+ \n",
    "                    join_date +\",\"+ \n",
    "                    post_date.replace(\",\",\"\") +\",\"+ \n",
    "                    num_likes + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing ###\n",
    "\n",
    "# Open a new file\n",
    "filename = \"hexes.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Test it out\n",
    "url = \"https://www.mountainproject.com/forum/topic/118116756/best-snag-free-very-light-trad-carabiner\"\n",
    "test_list = forum_scrape(url)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of url of all topics\n",
    "Then scrape that list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(main_discussion_url):\n",
    "    \"\"\"Get all subforum urls in a forum\"\"\"\n",
    "    # Get HTML info\n",
    "    uClient = uReq(main_discussion_url) # request the URL\n",
    "    page_html = uClient.read() # Read the html\n",
    "    uClient.close() # close the connection\n",
    "    \n",
    "    # How many pages of topics are there?\n",
    "    forum_soup = soup(page_html, \"html.parser\")\n",
    "    num_topic_pages_container = forum_soup.findAll(\"a\", {\"class\":\"no-click\"})\n",
    "    num_topic_pages = int(num_topic_pages_container[2].text.split(\"of \")[1].split(\"\\n\")[0])\n",
    "    print(\"Scraping %s pages of forum URLs.\" %num_topic_pages)\n",
    "    \n",
    "    url_list = []\n",
    "    for page in range(1, num_topic_pages+1):\n",
    "        if page == 1:\n",
    "            new_url = main_discussion_url\n",
    "        else: \n",
    "            new_url = main_discussion_url + \"?page=\" + str(page)\n",
    "        url_list.append(new_url)\n",
    "    \n",
    "    forum_list = []\n",
    "    for url in url_list:\n",
    "        time.sleep(.25)\n",
    "        # Get HTML info\n",
    "        uClient = uReq(url) # request the URL\n",
    "        page_html = uClient.read() # Read the html\n",
    "        uClient.close() # close the connection\n",
    "        \n",
    "        forum_soup = soup(page_html, \"html.parser\")\n",
    "        forum_container = forum_soup.findAll(\"table\", {\"class\":\"table width100 table-striped\"})\n",
    "        for a in forum_soup.find_all('a', href=True):\n",
    "            if \"topic/\" in a[\"href\"]:\n",
    "                if \"forum-topic\" not in a[\"href\"]:\n",
    "                    forum_list.append(a[\"href\"])\n",
    "                    \n",
    "    print(\"There are %s forum URLs\" %len(forum_list))   \n",
    "    \n",
    "    return forum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 261 pages of forum URLs.\n",
      "There are 10414 forum URLs\n",
      "Scraping 19 pages of forum URLs.\n",
      "There are 739 forum URLs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "183.49131202697754"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "main_url_discussion = \"https://www.mountainproject.com/forum/103989417/climbing-gear-discussion\"\n",
    "all_discussion_urls = get_topic_urls(main_url_discussion)\n",
    "\n",
    "main_url_reviews = \"https://www.mountainproject.com/forum/106123795/climbing-gear-reviews\"\n",
    "all_review_urls = get_topic_urls(main_url_reviews)\n",
    "\n",
    "t1 = time.time()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use list of URLs to scrape each forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865.2236521244049"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Open a new file\n",
    "filename = \"reviews.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Iterate over urls\n",
    "for url in all_review_urls:\n",
    "    forum_scrape(url)\n",
    "\n",
    "f.close()\n",
    "\n",
    "t1 = time.time()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'})\n",
    "response.status_code\n",
    "t0 = time.time()\n",
    "\n",
    "# Open a new file\n",
    "filename = \"discussion1.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Iterate over urls\n",
    "for url in all_discussion_urls:\n",
    "    forum_scrape(url)\n",
    "\n",
    "f.close()\n",
    "\n",
    "t1 = time.time()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell above got me 95722 rows\n",
    "\n",
    "I need to extract some more.\n",
    "\n",
    "The last forum scraped was \"GEAR4ROCKS is no more? I should have bought their plastic nuts when I had the chance!\" December 7, 2016 page 119.\n",
    "\n",
    "Next forum is \"Mammut Ropes\" December 6,2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5677"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Url of Mammut Ropes forum\n",
    "ropes_url = \"https://www.mountainproject.com/forum/topic/112350107/mammut-ropes\"\n",
    "\n",
    "# Find location of this forum in list of all urls\n",
    "ropes_index = all_discussion_urls.index(ropes_url)\n",
    "\n",
    "second_part_discussion_urls = all_discussion_urls[ropes_index:]\n",
    "len(second_part_discussion_urls) # 5677 urls left to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'})\n",
    "response.status_code\n",
    "t0 = time.time()\n",
    "\n",
    "# Open a new file\n",
    "filename = \"discussion2.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Iterate over urls\n",
    "for url in second_part_discussion_urls:\n",
    "    forum_scrape(url)\n",
    "\n",
    "f.close()\n",
    "\n",
    "t1 = time.time()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell above got me 27199 rows\n",
    "\n",
    "I need to extract the rest.\n",
    "\n",
    "The last forum scraped was \"EP Best Customer Service Ever\" January 8 2015, page 162.\n",
    "\n",
    "Next forum is \"Advice on stoves\" January 8,2015\n",
    "\n",
    "The code below will extract the rest. Run when you are ready. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3963"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Url of Advice on stoves forum\n",
    "stoves_url = \"https://www.mountainproject.com/forum/topic/109900178/advice-on-stoves\"\n",
    "\n",
    "# Find location of this forum in list of all urls\n",
    "stoves_index = all_discussion_urls.index(stoves_url)\n",
    "\n",
    "third_part_discussion_urls = all_discussion_urls[stoves_index:]\n",
    "len(third_part_discussion_urls) # 3963 urls left to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e9ad0dc33544ee94c2d4744536f039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3963.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9906.035131931305"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'})\n",
    "response.status_code\n",
    "t0 = time.time()\n",
    "\n",
    "# Open a new file\n",
    "filename = \"discussion3.csv\"\n",
    "f = open(filename, \"w\")\n",
    "headers = \"topic, page_num, post_num, text, join_date, post_date, num_likes\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Iterate over urls\n",
    "for url in tqdm(third_part_discussion_urls):\n",
    "    forum_scrape(url)\n",
    "\n",
    "f.close()\n",
    "\n",
    "t1 = time.time()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup discussion forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "disc_filenames = [i for i in all_filenames if \"discussion\" in i]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in disc_filenames ])\n",
    "\n",
    "#export to csv\n",
    "combined_csv.to_csv(\"discussion_forum.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>post_num</th>\n",
       "      <th>text</th>\n",
       "      <th>join_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>Have a hammock gear quilt right now.  I reall...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you roll or stuff the quilt when not in us...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>I stuff it and every night the down ends up a...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>t</td>\n",
       "      <td>3</td>\n",
       "      <td>I've had one of the Katabatic 20 degree quilt...</td>\n",
       "      <td>Jun 2016</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I know this is kind of old news~ but what is ...</td>\n",
       "      <td>Jun 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adidas has owned 5.10 since 2011~ longer than...</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I think overwhelmingly~ the change has hurt t...</td>\n",
       "      <td>Jul 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Meh. That may have been when there was a tran...</td>\n",
       "      <td>Jan 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>I dunno about the rubber~ but I have some moc...</td>\n",
       "      <td>Nov 2018</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>I wore guide tennis before and after Adidas t...</td>\n",
       "      <td>Oct 2008</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Big issue with sizing changes and durability ...</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>same story here with approach shoes</td>\n",
       "      <td>Mar 2016</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>#fakenews</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Sizing from adidas is a huge issue - if I fin...</td>\n",
       "      <td>Apr 2007</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>I never had the american made shoes~ but the ...</td>\n",
       "      <td>Oct 2016</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>My own previous snarkiness aside~ I’ve experi...</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Yeah I would say of the major brands~ the big...</td>\n",
       "      <td>Jul 2014</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Same here. I haven't been climbing long enoug...</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>I’ve been using 5.10 since they started and d...</td>\n",
       "      <td>Apr 2012</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>I have some guide tennies from before and aft...</td>\n",
       "      <td>Sep 2013</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>FWIW~ I love my 5.10 Quantum lace-ups and the...</td>\n",
       "      <td>Jan 2019</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>I think any current 5.10 issues were also pre...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5.10 quality was always inferior to the Europ...</td>\n",
       "      <td>May 2015</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Delam issues are not always the manufacturers...</td>\n",
       "      <td>Apr 2012</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>I'm old...53 to be exact~ and I have not had ...</td>\n",
       "      <td>Jul 2015</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly disagree.  I used to order 1-2 pairs...</td>\n",
       "      <td>Apr 2007</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I started using 5.10 in 1996.  Before that I ...</td>\n",
       "      <td>Feb 2012</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Second this comment.  Guide Tennis were my fa...</td>\n",
       "      <td>Feb 2014</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>I know a few sponsored climbers and apparentl...</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>Nov 23 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I generally like 5.10 shoes and have owned ma...</td>\n",
       "      <td>Feb 2013</td>\n",
       "      <td>Nov 25 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              topic page_num  post_num  \\\n",
       "0   Katabatic quilts and down shift        t         0   \n",
       "1   Katabatic quilts and down shift        t         1   \n",
       "2   Katabatic quilts and down shift        t         2   \n",
       "3   Katabatic quilts and down shift        t         3   \n",
       "4                Adidas owning 5.10        0         0   \n",
       "5                Adidas owning 5.10        0         1   \n",
       "6                Adidas owning 5.10        0         2   \n",
       "7                Adidas owning 5.10        0         3   \n",
       "8                Adidas owning 5.10        0         4   \n",
       "9                Adidas owning 5.10        0         5   \n",
       "10               Adidas owning 5.10        0         6   \n",
       "11               Adidas owning 5.10        0         7   \n",
       "12               Adidas owning 5.10        0         8   \n",
       "13               Adidas owning 5.10        0         9   \n",
       "14               Adidas owning 5.10        0        10   \n",
       "15               Adidas owning 5.10        0        11   \n",
       "16               Adidas owning 5.10        0        12   \n",
       "17               Adidas owning 5.10        0        13   \n",
       "18               Adidas owning 5.10        0        14   \n",
       "19               Adidas owning 5.10        0        15   \n",
       "20               Adidas owning 5.10        0        16   \n",
       "21               Adidas owning 5.10        0        17   \n",
       "22               Adidas owning 5.10        0        18   \n",
       "23               Adidas owning 5.10        0        19   \n",
       "24               Adidas owning 5.10        0        20   \n",
       "25               Adidas owning 5.10        2         0   \n",
       "26               Adidas owning 5.10        2         1   \n",
       "27               Adidas owning 5.10        2         2   \n",
       "28               Adidas owning 5.10        2         3   \n",
       "29               Adidas owning 5.10        2         4   \n",
       "\n",
       "                                                 text join_date    post_date  \\\n",
       "0    Have a hammock gear quilt right now.  I reall...  Jan 2012    1 day ago   \n",
       "1    Do you roll or stuff the quilt when not in us...  Mar 2020    1 day ago   \n",
       "2    I stuff it and every night the down ends up a...  Jan 2012  4 hours ago   \n",
       "3    I've had one of the Katabatic 20 degree quilt...  Jun 2016  4 hours ago   \n",
       "4    I know this is kind of old news~ but what is ...  Jun 2017  Nov 21 2019   \n",
       "5    Adidas has owned 5.10 since 2011~ longer than...  Aug 2019  Nov 21 2019   \n",
       "6    I think overwhelmingly~ the change has hurt t...  Jul 2017  Nov 21 2019   \n",
       "7    Meh. That may have been when there was a tran...  Jan 2017  Nov 21 2019   \n",
       "8    I dunno about the rubber~ but I have some moc...  Nov 2018  Nov 21 2019   \n",
       "9    I wore guide tennis before and after Adidas t...  Oct 2008  Nov 21 2019   \n",
       "10   Big issue with sizing changes and durability ...  Sep 2019  Nov 21 2019   \n",
       "11                same story here with approach shoes  Mar 2016  Nov 21 2019   \n",
       "12                                          #fakenews  Oct 2019  Nov 21 2019   \n",
       "13   Sizing from adidas is a huge issue - if I fin...  Apr 2007  Nov 21 2019   \n",
       "14   I never had the american made shoes~ but the ...  Oct 2016  Nov 21 2019   \n",
       "15   My own previous snarkiness aside~ I’ve experi...  Aug 2019  Nov 21 2019   \n",
       "16   Yeah I would say of the major brands~ the big...  Jul 2014  Nov 21 2019   \n",
       "17   Same here. I haven't been climbing long enoug...  Jul 2019  Nov 21 2019   \n",
       "18   I’ve been using 5.10 since they started and d...  Apr 2012  Nov 22 2019   \n",
       "19   I have some guide tennies from before and aft...  Sep 2013  Nov 22 2019   \n",
       "20   FWIW~ I love my 5.10 Quantum lace-ups and the...  Jan 2019  Nov 22 2019   \n",
       "21   I think any current 5.10 issues were also pre...  Jan 2012  Nov 22 2019   \n",
       "22   5.10 quality was always inferior to the Europ...  May 2015  Nov 22 2019   \n",
       "23   Delam issues are not always the manufacturers...  Apr 2012  Nov 22 2019   \n",
       "24   I'm old...53 to be exact~ and I have not had ...  Jul 2015  Nov 22 2019   \n",
       "25   Strongly disagree.  I used to order 1-2 pairs...  Apr 2007  Nov 22 2019   \n",
       "26   I started using 5.10 in 1996.  Before that I ...  Feb 2012  Nov 22 2019   \n",
       "27   Second this comment.  Guide Tennis were my fa...  Feb 2014  Nov 22 2019   \n",
       "28   I know a few sponsored climbers and apparentl...  May 2017  Nov 23 2019   \n",
       "29   I generally like 5.10 shoes and have owned ma...  Feb 2013  Nov 25 2019   \n",
       "\n",
       "    num_likes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5          22  \n",
       "6           7  \n",
       "7          12  \n",
       "8           0  \n",
       "9           7  \n",
       "10          2  \n",
       "11          4  \n",
       "12          1  \n",
       "13          4  \n",
       "14          0  \n",
       "15          4  \n",
       "16          0  \n",
       "17          1  \n",
       "18          2  \n",
       "19          3  \n",
       "20          0  \n",
       "21          2  \n",
       "22          2  \n",
       "23          3  \n",
       "24          1  \n",
       "25          1  \n",
       "26          0  \n",
       "27          0  \n",
       "28          1  \n",
       "29          0  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"discussion_forum.csv\")\n",
    "df = df.rename(columns=lambda x: x.strip()) # remove whitespace from col names\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>post_num</th>\n",
       "      <th>text</th>\n",
       "      <th>join_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Have a hammock gear quilt right now.  I reall...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you roll or stuff the quilt when not in us...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I stuff it and every night the down ends up a...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I've had one of the Katabatic 20 degree quilt...</td>\n",
       "      <td>Jun 2016</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I know this is kind of old news~ but what is ...</td>\n",
       "      <td>Jun 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Adidas has owned 5.10 since 2011~ longer than...</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I think overwhelmingly~ the change has hurt t...</td>\n",
       "      <td>Jul 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Meh. That may have been when there was a tran...</td>\n",
       "      <td>Jan 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>I dunno about the rubber~ but I have some moc...</td>\n",
       "      <td>Nov 2018</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I wore guide tennis before and after Adidas t...</td>\n",
       "      <td>Oct 2008</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Big issue with sizing changes and durability ...</td>\n",
       "      <td>Sep 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>same story here with approach shoes</td>\n",
       "      <td>Mar 2016</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>#fakenews</td>\n",
       "      <td>Oct 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Sizing from adidas is a huge issue - if I fin...</td>\n",
       "      <td>Apr 2007</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>I never had the american made shoes~ but the ...</td>\n",
       "      <td>Oct 2016</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>My own previous snarkiness aside~ I’ve experi...</td>\n",
       "      <td>Aug 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Yeah I would say of the major brands~ the big...</td>\n",
       "      <td>Jul 2014</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Same here. I haven't been climbing long enoug...</td>\n",
       "      <td>Jul 2019</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>I’ve been using 5.10 since they started and d...</td>\n",
       "      <td>Apr 2012</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>I have some guide tennies from before and aft...</td>\n",
       "      <td>Sep 2013</td>\n",
       "      <td>Nov 22 2019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              topic page_num  post_num  \\\n",
       "0   Katabatic quilts and down shift        1         0   \n",
       "1   Katabatic quilts and down shift        1         1   \n",
       "2   Katabatic quilts and down shift        1         2   \n",
       "3   Katabatic quilts and down shift        1         3   \n",
       "4                Adidas owning 5.10        1         0   \n",
       "5                Adidas owning 5.10        1         1   \n",
       "6                Adidas owning 5.10        1         2   \n",
       "7                Adidas owning 5.10        1         3   \n",
       "8                Adidas owning 5.10        1         4   \n",
       "9                Adidas owning 5.10        1         5   \n",
       "10               Adidas owning 5.10        1         6   \n",
       "11               Adidas owning 5.10        1         7   \n",
       "12               Adidas owning 5.10        1         8   \n",
       "13               Adidas owning 5.10        1         9   \n",
       "14               Adidas owning 5.10        1        10   \n",
       "15               Adidas owning 5.10        1        11   \n",
       "16               Adidas owning 5.10        1        12   \n",
       "17               Adidas owning 5.10        1        13   \n",
       "18               Adidas owning 5.10        1        14   \n",
       "19               Adidas owning 5.10        1        15   \n",
       "\n",
       "                                                 text join_date    post_date  \\\n",
       "0    Have a hammock gear quilt right now.  I reall...  Jan 2012    1 day ago   \n",
       "1    Do you roll or stuff the quilt when not in us...  Mar 2020    1 day ago   \n",
       "2    I stuff it and every night the down ends up a...  Jan 2012  4 hours ago   \n",
       "3    I've had one of the Katabatic 20 degree quilt...  Jun 2016  4 hours ago   \n",
       "4    I know this is kind of old news~ but what is ...  Jun 2017  Nov 21 2019   \n",
       "5    Adidas has owned 5.10 since 2011~ longer than...  Aug 2019  Nov 21 2019   \n",
       "6    I think overwhelmingly~ the change has hurt t...  Jul 2017  Nov 21 2019   \n",
       "7    Meh. That may have been when there was a tran...  Jan 2017  Nov 21 2019   \n",
       "8    I dunno about the rubber~ but I have some moc...  Nov 2018  Nov 21 2019   \n",
       "9    I wore guide tennis before and after Adidas t...  Oct 2008  Nov 21 2019   \n",
       "10   Big issue with sizing changes and durability ...  Sep 2019  Nov 21 2019   \n",
       "11                same story here with approach shoes  Mar 2016  Nov 21 2019   \n",
       "12                                          #fakenews  Oct 2019  Nov 21 2019   \n",
       "13   Sizing from adidas is a huge issue - if I fin...  Apr 2007  Nov 21 2019   \n",
       "14   I never had the american made shoes~ but the ...  Oct 2016  Nov 21 2019   \n",
       "15   My own previous snarkiness aside~ I’ve experi...  Aug 2019  Nov 21 2019   \n",
       "16   Yeah I would say of the major brands~ the big...  Jul 2014  Nov 21 2019   \n",
       "17   Same here. I haven't been climbing long enoug...  Jul 2019  Nov 21 2019   \n",
       "18   I’ve been using 5.10 since they started and d...  Apr 2012  Nov 22 2019   \n",
       "19   I have some guide tennies from before and aft...  Sep 2013  Nov 22 2019   \n",
       "\n",
       "    num_likes  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5          22  \n",
       "6           7  \n",
       "7          12  \n",
       "8           0  \n",
       "9           7  \n",
       "10          2  \n",
       "11          4  \n",
       "12          1  \n",
       "13          4  \n",
       "14          0  \n",
       "15          4  \n",
       "16          0  \n",
       "17          1  \n",
       "18          2  \n",
       "19          3  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the page_num column\n",
    "\n",
    "for i in range(len(df[\"page_num\"])):\n",
    "    try:\n",
    "        df[\"page_num\"][i] = int(df[\"page_num\"][i])\n",
    "    except:\n",
    "        df[\"page_num\"][i] = 1\n",
    "    if df[\"page_num\"][i] == 0:\n",
    "        df[\"page_num\"][i] = 1\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>post_num</th>\n",
       "      <th>text</th>\n",
       "      <th>join_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Have a hammock gear quilt right now.  I reall...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>Jul 5 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you roll or stuff the quilt when not in us...</td>\n",
       "      <td>Mar 2020</td>\n",
       "      <td>Jul 5 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I stuff it and every night the down ends up a...</td>\n",
       "      <td>Jan 2012</td>\n",
       "      <td>Jul 6 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katabatic quilts and down shift</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I've had one of the Katabatic 20 degree quilt...</td>\n",
       "      <td>Jun 2016</td>\n",
       "      <td>Jul 6 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adidas owning 5.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I know this is kind of old news~ but what is ...</td>\n",
       "      <td>Jun 2017</td>\n",
       "      <td>Nov 21 2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             topic page_num  post_num  \\\n",
       "0  Katabatic quilts and down shift        1         0   \n",
       "1  Katabatic quilts and down shift        1         1   \n",
       "2  Katabatic quilts and down shift        1         2   \n",
       "3  Katabatic quilts and down shift        1         3   \n",
       "4               Adidas owning 5.10        1         0   \n",
       "\n",
       "                                                text join_date    post_date  \\\n",
       "0   Have a hammock gear quilt right now.  I reall...  Jan 2012   Jul 5 2020   \n",
       "1   Do you roll or stuff the quilt when not in us...  Mar 2020   Jul 5 2020   \n",
       "2   I stuff it and every night the down ends up a...  Jan 2012   Jul 6 2020   \n",
       "3   I've had one of the Katabatic 20 degree quilt...  Jun 2016   Jul 6 2020   \n",
       "4   I know this is kind of old news~ but what is ...  Jun 2017  Nov 21 2019   \n",
       "\n",
       "   num_likes  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the post date column\n",
    "date_change_needed = [date for date in df.post_date.unique() if \"ago\" in date]\n",
    "\n",
    "date_dict = {7:\"Jun 29 2020\",\n",
    "            6:\"Jun 30 2020\",\n",
    "            5:\"Jul 1 2020\",\n",
    "            4:\"Jul 2 2020\",\n",
    "            3:\"Jul 3 2020\",\n",
    "            2:\"Jul 4 2020\",\n",
    "            1: \"Jul 5 2020\"}\n",
    "\n",
    "replacement_dates = dict()\n",
    "for date in date_change_needed:\n",
    "    if \"hour\" in date:\n",
    "        replacement_dates[date] = \"Jul 6 2020\"\n",
    "        continue\n",
    "    if \"min\" in date:\n",
    "        replacement_dates[date] = \"Jul 6 2020\"\n",
    "        continue\n",
    "    if \"7\" in date:\n",
    "        replacement_dates[date] = date_dict[7]\n",
    "    if \"6\" in date:\n",
    "        replacement_dates[date] = date_dict[6]\n",
    "    if \"5\" in date:\n",
    "        replacement_dates[date] = date_dict[5]\n",
    "    if \"4\" in date:\n",
    "        replacement_dates[date] = date_dict[4]\n",
    "    if \"3\" in date:\n",
    "        replacement_dates[date] = date_dict[3]\n",
    "    if \"2\" in date:\n",
    "        replacement_dates[date] = date_dict[2]\n",
    "    if \"1\" in date:\n",
    "        replacement_dates[date] = date_dict[1]\n",
    "\n",
    "for i in range(len(df[\"post_date\"])):\n",
    "    try:\n",
    "        df[\"post_date\"][i] = replacement_dates[df[\"post_date\"][i]]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jan 2012', 'Mar 2020', 'Jun 2016', 'Jun 2017', 'Aug 2019',\n",
       "       'Jul 2017', 'Jan 2017', 'Nov 2018', 'Oct 2008', 'Sep 2019',\n",
       "       'Mar 2016', 'Oct 2019', 'Apr 2007', 'Oct 2016', 'Jul 2014',\n",
       "       'Jul 2019', 'Apr 2012', 'Sep 2013', 'Jan 2019', 'May 2015',\n",
       "       'Jul 2015', 'Feb 2012', 'Feb 2014', 'May 2017', 'Feb 2013',\n",
       "       'Jul 2018', 'Aug 2009', 'Apr 2010', 'May 2020', 'Aug 2008',\n",
       "       'Mar 2014', 'Jan 2013', 'Jan 2016', 'Sep 2010', 'Oct 2013',\n",
       "       'Aug 2016', 'Jul 2010', 'Sep 2018', 'Feb 2008', 'Nov 2015',\n",
       "       'Mar 2009', 'Feb 2015', 'Jun 2019', 'Jan 2001', 'Feb 2006',\n",
       "       'Mar 2006', 'Jun 2020', 'Nov 2017', 'Mar 2019', 'Aug 2018',\n",
       "       'Dec 2013', 'Dec 2009', 'Nov 2009', 'Apr 2019', 'Mar 2018',\n",
       "       'Aug 2015', 'Jun 2013', 'Apr 2017', 'Feb 2016', 'Nov 2006',\n",
       "       'Oct 2015', 'Dec 2008', 'Dec 2015', 'Jun 2015', 'May 2016',\n",
       "       'Sep 2017', 'Oct 2007', 'May 2014', 'Jun 2018', 'May 2018',\n",
       "       'Apr 2018', 'Jun 2014', 'Apr 2013', 'Oct 2011', 'Jan 2008',\n",
       "       'Dec 2019', 'Nov 2019', 'Oct 2017', 'Dec 2004', 'Dec 2011',\n",
       "       'Aug 2012', 'Apr 2015', 'Aug 2014', 'Jul 2012', 'Dec 2017',\n",
       "       'Apr 2006', 'Apr 2020', 'Apr 2016', 'Jul 2006', 'Aug 2017',\n",
       "       'Oct 2002', 'Feb 2017', 'Sep 2012', 'Jun 2010', 'Jul 2009',\n",
       "       'Sep 2006', 'unknown', 'Feb 2018', 'Feb 2020', 'May 2019',\n",
       "       'Sep 2016', 'Oct 2010', 'Apr 2014', 'Jan 2007', 'Jul 2016',\n",
       "       'Aug 2013', 'Mar 2017', 'Oct 2018', 'Feb 2010', 'Jan 2020',\n",
       "       'Jul 2007', 'Mar 2008', 'Sep 2015', 'Jan 2009', 'Apr 2011',\n",
       "       'Nov 2014', 'May 2010', 'Dec 2014', 'Nov 2011', 'Mar 2015',\n",
       "       'Nov 2005', 'Sep 2014', 'Jun 2011', 'Dec 2010', 'Dec 2012',\n",
       "       'Jun 2012', 'Mar 2013', 'May 2012', 'Nov 2010', 'Feb 2019',\n",
       "       'Jun 2001', 'Nov 2008', 'Nov 2012', 'May 2013', 'May 2003',\n",
       "       'Jun 2006', 'Feb 2009', 'Oct 2014', 'Jun 2007', 'Jan 2014',\n",
       "       'Jan 2015', 'Jul 2005', 'Feb 2011', 'Nov 2013', 'May 2006',\n",
       "       'Oct 2003', 'Oct 2012', 'Dec 2005', 'May 2007', 'Nov 2004',\n",
       "       'May 2011', 'Sep 2005', 'Jul 2013', 'Apr 2004', 'Jan 2006',\n",
       "       'Sep 2009', 'Dec 2018', 'Jan 2018', 'Aug 2011', 'Dec 2016',\n",
       "       'Jun 2004', 'Aug 2010', 'Mar 2011', 'Aug 2007', 'Jan 2011',\n",
       "       'May 2009', 'Apr 2009', 'Aug 2002', 'Oct 2009', 'Jan 2010',\n",
       "       'Aug 2003', 'Mar 2012', 'Nov 2007', 'Jun 2008', 'Jul 2008',\n",
       "       'Mar 2010', 'Oct 2004', 'Nov 2016', 'Jun 2009', 'Jul 2011',\n",
       "       'May 2008', 'Apr 2008', 'Oct 2005', 'Mar 2002', 'Sep 2007',\n",
       "       'Dec 2002', 'Nov 2001', 'Feb 2003', 'Sep 2011', 'Apr 2003',\n",
       "       'Nov 2003', 'Sep 2008', 'May 2002', 'Jul 2003', 'Dec 2007',\n",
       "       'Oct 2006', 'Dec 2006', 'Jul 2004', 'Feb 2007', 'Aug 2004',\n",
       "       'Mar 2007', 'Aug 2006', 'Jan 2002', 'Mar 2001', 'Aug 2001',\n",
       "       'Feb 2005', 'Sep 2003', 'Sep 2002', 'Jul 2002', 'Sep 2001',\n",
       "       'Jan 2004', 'Apr 2002', 'Dec 2003', 'Mar 2004', 'Jun 2002',\n",
       "       'Feb 2002', 'Jan 2003', 'Oct 2001', 'Jan 2005', 'Jul 2001',\n",
       "       'Feb 2004', 'Apr 2001', 'Mar 2005', 'Dec 2001', 'May 2005',\n",
       "       'Mar 2003', 'May 2004', 'Nov 2002', 'Jun 2005', 'Aug 2005',\n",
       "       'Jun 2003', 'May 2001', 'Jan 2000', 'Apr 2005', 'Sep 2004'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up join_date column\n",
    "date_change_needed = []\n",
    "for date in df.join_date.unique():\n",
    "    if \"20\" not in date:\n",
    "        if \"19\" not in date:\n",
    "            date_change_needed.append(date)\n",
    "            \n",
    "for i in range(len(df[\"join_date\"])):\n",
    "    if df[\"join_date\"][i] == \"unknown\":\n",
    "        df[\"join_date\"][i] == np.nan\n",
    "        continue\n",
    "    if df[\"join_date\"][i] in date_change_needed:\n",
    "        df[\"join_date\"][i] = \"Jun 2020\"\n",
    "df.join_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/patriciadegner/Documents/MIDS/DL/final_project'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/patriciadegner/Documents/MIDS/DL/final_project/discussion_forum.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup review forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>post_num</th>\n",
       "      <th>text</th>\n",
       "      <th>join_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi all~ I am in the market for a new plaquett...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>Easiest on the elbows would definitely be a G...</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>DMM Pivot</td>\n",
       "      <td>Mar 2019</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>Both the Pivot and the ATC guide accept ropes...</td>\n",
       "      <td>Jun 2015</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>4</td>\n",
       "      <td>Thanks Adam! As a clarification~ When climbin...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>5</td>\n",
       "      <td>Right on~ Chris.  In that case~ the Pivot is ...</td>\n",
       "      <td>Jun 2015</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>6</td>\n",
       "      <td>grigri</td>\n",
       "      <td>Sep 2010</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>7</td>\n",
       "      <td>To be fair~ a Gigi adds very little weight or...</td>\n",
       "      <td>Aug 2011</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>8</td>\n",
       "      <td>I cannot speak from direct experience~ but I ...</td>\n",
       "      <td>Aug 2013</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>9</td>\n",
       "      <td>Hey Karl~ Thanks for your reply. I have tried...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>10</td>\n",
       "      <td>If you liked the Gigajul~ except for the rela...</td>\n",
       "      <td>Aug 2013</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>11</td>\n",
       "      <td>did you try the gigajul or megajul? i've had ...</td>\n",
       "      <td>Sep 2016</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>12</td>\n",
       "      <td>This chart is a bit dated. It comes from an o...</td>\n",
       "      <td>Aug 2008</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>13</td>\n",
       "      <td>+1 for pivot</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>14</td>\n",
       "      <td>Marty~ That is an interesting chart. This is ...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 20 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 20 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>16</td>\n",
       "      <td>Ovo or Gigi.  Weighs nothing~ easy pull.  Yo...</td>\n",
       "      <td>Nov 2015</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>e</td>\n",
       "      <td>17</td>\n",
       "      <td>I've used a few of the other devices mentione...</td>\n",
       "      <td>Apr 2015</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>Does anyone have experience with the Up Mocc ...</td>\n",
       "      <td>Jan 2013</td>\n",
       "      <td>Jun 17 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>I got them because the mocs aren't what they ...</td>\n",
       "      <td>Jun 2013</td>\n",
       "      <td>Jun 17 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "      <td>UpMocc wont stretch as much as the 5.10 mocc</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>Jun 17 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>3</td>\n",
       "      <td>The up mocc does not stretch much at all~ I s...</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "      <td>Very helpful. Thanks all.</td>\n",
       "      <td>Jan 2013</td>\n",
       "      <td>Jun 21 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>s</td>\n",
       "      <td>5</td>\n",
       "      <td>I picked up the UP Moccs a couple months ago ...</td>\n",
       "      <td>Apr 2015</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>Arc'Teryx's warranty is useless. I own a lot ...</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>1</td>\n",
       "      <td>I’ve heard that sometimes it can really depen...</td>\n",
       "      <td>Apr 2020</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "      <td>I have noticed a general theme as well. Patag...</td>\n",
       "      <td>Dec 2015</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>3</td>\n",
       "      <td>They recently repaired a zipper for me~ no qu...</td>\n",
       "      <td>Jun 2016</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "      <td>I've had Outdoor Research and Mountain Hardwe...</td>\n",
       "      <td>Jul 2013</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Arc'Teryx warranty is meaningless</td>\n",
       "      <td>s</td>\n",
       "      <td>5</td>\n",
       "      <td>Demanding a repair on 10 year old SHORTS?? Co...</td>\n",
       "      <td>Apr 2020</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                topic page_num  post_num  \\\n",
       "0        Plaquette/Guide Style Device        e         0   \n",
       "1        Plaquette/Guide Style Device        e         1   \n",
       "2        Plaquette/Guide Style Device        e         2   \n",
       "3        Plaquette/Guide Style Device        e         3   \n",
       "4        Plaquette/Guide Style Device        e         4   \n",
       "5        Plaquette/Guide Style Device        e         5   \n",
       "6        Plaquette/Guide Style Device        e         6   \n",
       "7        Plaquette/Guide Style Device        e         7   \n",
       "8        Plaquette/Guide Style Device        e         8   \n",
       "9        Plaquette/Guide Style Device        e         9   \n",
       "10       Plaquette/Guide Style Device        e        10   \n",
       "11       Plaquette/Guide Style Device        e        11   \n",
       "12       Plaquette/Guide Style Device        e        12   \n",
       "13       Plaquette/Guide Style Device        e        13   \n",
       "14       Plaquette/Guide Style Device        e        14   \n",
       "15       Plaquette/Guide Style Device        e        15   \n",
       "16       Plaquette/Guide Style Device        e        16   \n",
       "17       Plaquette/Guide Style Device        e        17   \n",
       "18                  Up Mocc questions        s         0   \n",
       "19                  Up Mocc questions        s         1   \n",
       "20                  Up Mocc questions        s         2   \n",
       "21                  Up Mocc questions        s         3   \n",
       "22                  Up Mocc questions        s         4   \n",
       "23                  Up Mocc questions        s         5   \n",
       "24  Arc'Teryx warranty is meaningless        s         0   \n",
       "25  Arc'Teryx warranty is meaningless        s         1   \n",
       "26  Arc'Teryx warranty is meaningless        s         2   \n",
       "27  Arc'Teryx warranty is meaningless        s         3   \n",
       "28  Arc'Teryx warranty is meaningless        s         4   \n",
       "29  Arc'Teryx warranty is meaningless        s         5   \n",
       "\n",
       "                                                 text  join_date    post_date  \\\n",
       "0    Hi all~ I am in the market for a new plaquett...   Sep 2017  Jun 19 2020   \n",
       "1    Easiest on the elbows would definitely be a G...   May 2006  Jun 19 2020   \n",
       "2                                           DMM Pivot   Mar 2019  Jun 19 2020   \n",
       "3    Both the Pivot and the ATC guide accept ropes...   Jun 2015  Jun 19 2020   \n",
       "4    Thanks Adam! As a clarification~ When climbin...   Sep 2017  Jun 19 2020   \n",
       "5    Right on~ Chris.  In that case~ the Pivot is ...   Jun 2015  Jun 19 2020   \n",
       "6                                              grigri   Sep 2010  Jun 19 2020   \n",
       "7    To be fair~ a Gigi adds very little weight or...   Aug 2011  Jun 19 2020   \n",
       "8    I cannot speak from direct experience~ but I ...   Aug 2013  Jun 19 2020   \n",
       "9    Hey Karl~ Thanks for your reply. I have tried...   Sep 2017  Jun 19 2020   \n",
       "10   If you liked the Gigajul~ except for the rela...   Aug 2013  Jun 19 2020   \n",
       "11   did you try the gigajul or megajul? i've had ...   Sep 2016  Jun 19 2020   \n",
       "12   This chart is a bit dated. It comes from an o...   Aug 2008  Jun 19 2020   \n",
       "13                                      +1 for pivot    Feb 2020  Jun 19 2020   \n",
       "14   Marty~ That is an interesting chart. This is ...   Sep 2017  Jun 20 2020   \n",
       "15                                                NaN   Sep 2017  Jun 20 2020   \n",
       "16    Ovo or Gigi.  Weighs nothing~ easy pull.  Yo...   Nov 2015   2 days ago   \n",
       "17   I've used a few of the other devices mentione...   Apr 2015    1 day ago   \n",
       "18   Does anyone have experience with the Up Mocc ...   Jan 2013  Jun 17 2020   \n",
       "19   I got them because the mocs aren't what they ...   Jun 2013  Jun 17 2020   \n",
       "20       UpMocc wont stretch as much as the 5.10 mocc   May 2017  Jun 17 2020   \n",
       "21   The up mocc does not stretch much at all~ I s...   May 2017  Jun 19 2020   \n",
       "22                         Very helpful. Thanks all.    Jan 2013  Jun 21 2020   \n",
       "23   I picked up the UP Moccs a couple months ago ...   Apr 2015    1 day ago   \n",
       "24   Arc'Teryx's warranty is useless. I own a lot ...  1 day ago   3 days ago   \n",
       "25   I’ve heard that sometimes it can really depen...   Apr 2020   2 days ago   \n",
       "26   I have noticed a general theme as well. Patag...   Dec 2015   2 days ago   \n",
       "27   They recently repaired a zipper for me~ no qu...   Jun 2016   2 days ago   \n",
       "28   I've had Outdoor Research and Mountain Hardwe...   Jul 2013   2 days ago   \n",
       "29   Demanding a repair on 10 year old SHORTS?? Co...   Apr 2020   2 days ago   \n",
       "\n",
       "    num_likes  \n",
       "0           0  \n",
       "1           1  \n",
       "2           4  \n",
       "3           0  \n",
       "4           0  \n",
       "5           1  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          1  \n",
       "11          0  \n",
       "12          5  \n",
       "13          1  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          1  \n",
       "20          1  \n",
       "21          3  \n",
       "22          0  \n",
       "23          1  \n",
       "24          1  \n",
       "25          4  \n",
       "26          0  \n",
       "27          1  \n",
       "28          0  \n",
       "29         23  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"review_forum.csv\")\n",
    "df = df.rename(columns=lambda x: x.strip()) # remove whitespace from col names\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>post_num</th>\n",
       "      <th>text</th>\n",
       "      <th>join_date</th>\n",
       "      <th>post_date</th>\n",
       "      <th>num_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi all~ I am in the market for a new plaquett...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Easiest on the elbows would definitely be a G...</td>\n",
       "      <td>May 2006</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DMM Pivot</td>\n",
       "      <td>Mar 2019</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Both the Pivot and the ATC guide accept ropes...</td>\n",
       "      <td>Jun 2015</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Thanks Adam! As a clarification~ When climbin...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Right on~ Chris.  In that case~ the Pivot is ...</td>\n",
       "      <td>Jun 2015</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>grigri</td>\n",
       "      <td>Sep 2010</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>To be fair~ a Gigi adds very little weight or...</td>\n",
       "      <td>Aug 2011</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>I cannot speak from direct experience~ but I ...</td>\n",
       "      <td>Aug 2013</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Hey Karl~ Thanks for your reply. I have tried...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>If you liked the Gigajul~ except for the rela...</td>\n",
       "      <td>Aug 2013</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>did you try the gigajul or megajul? i've had ...</td>\n",
       "      <td>Sep 2016</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>This chart is a bit dated. It comes from an o...</td>\n",
       "      <td>Aug 2008</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>+1 for pivot</td>\n",
       "      <td>Feb 2020</td>\n",
       "      <td>Jun 19 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Marty~ That is an interesting chart. This is ...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 20 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Jun 20 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>Ovo or Gigi.  Weighs nothing~ easy pull.  Yo...</td>\n",
       "      <td>Nov 2015</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Plaquette/Guide Style Device</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>I've used a few of the other devices mentione...</td>\n",
       "      <td>Apr 2015</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Does anyone have experience with the Up Mocc ...</td>\n",
       "      <td>Jan 2013</td>\n",
       "      <td>Jun 17 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Up Mocc questions</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I got them because the mocs aren't what they ...</td>\n",
       "      <td>Jun 2013</td>\n",
       "      <td>Jun 17 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           topic page_num  post_num  \\\n",
       "0   Plaquette/Guide Style Device        1         0   \n",
       "1   Plaquette/Guide Style Device        1         1   \n",
       "2   Plaquette/Guide Style Device        1         2   \n",
       "3   Plaquette/Guide Style Device        1         3   \n",
       "4   Plaquette/Guide Style Device        1         4   \n",
       "5   Plaquette/Guide Style Device        1         5   \n",
       "6   Plaquette/Guide Style Device        1         6   \n",
       "7   Plaquette/Guide Style Device        1         7   \n",
       "8   Plaquette/Guide Style Device        1         8   \n",
       "9   Plaquette/Guide Style Device        1         9   \n",
       "10  Plaquette/Guide Style Device        1        10   \n",
       "11  Plaquette/Guide Style Device        1        11   \n",
       "12  Plaquette/Guide Style Device        1        12   \n",
       "13  Plaquette/Guide Style Device        1        13   \n",
       "14  Plaquette/Guide Style Device        1        14   \n",
       "15  Plaquette/Guide Style Device        1        15   \n",
       "16  Plaquette/Guide Style Device        1        16   \n",
       "17  Plaquette/Guide Style Device        1        17   \n",
       "18             Up Mocc questions        1         0   \n",
       "19             Up Mocc questions        1         1   \n",
       "\n",
       "                                                 text join_date    post_date  \\\n",
       "0    Hi all~ I am in the market for a new plaquett...  Sep 2017  Jun 19 2020   \n",
       "1    Easiest on the elbows would definitely be a G...  May 2006  Jun 19 2020   \n",
       "2                                           DMM Pivot  Mar 2019  Jun 19 2020   \n",
       "3    Both the Pivot and the ATC guide accept ropes...  Jun 2015  Jun 19 2020   \n",
       "4    Thanks Adam! As a clarification~ When climbin...  Sep 2017  Jun 19 2020   \n",
       "5    Right on~ Chris.  In that case~ the Pivot is ...  Jun 2015  Jun 19 2020   \n",
       "6                                              grigri  Sep 2010  Jun 19 2020   \n",
       "7    To be fair~ a Gigi adds very little weight or...  Aug 2011  Jun 19 2020   \n",
       "8    I cannot speak from direct experience~ but I ...  Aug 2013  Jun 19 2020   \n",
       "9    Hey Karl~ Thanks for your reply. I have tried...  Sep 2017  Jun 19 2020   \n",
       "10   If you liked the Gigajul~ except for the rela...  Aug 2013  Jun 19 2020   \n",
       "11   did you try the gigajul or megajul? i've had ...  Sep 2016  Jun 19 2020   \n",
       "12   This chart is a bit dated. It comes from an o...  Aug 2008  Jun 19 2020   \n",
       "13                                      +1 for pivot   Feb 2020  Jun 19 2020   \n",
       "14   Marty~ That is an interesting chart. This is ...  Sep 2017  Jun 20 2020   \n",
       "15                                                NaN  Sep 2017  Jun 20 2020   \n",
       "16    Ovo or Gigi.  Weighs nothing~ easy pull.  Yo...  Nov 2015   2 days ago   \n",
       "17   I've used a few of the other devices mentione...  Apr 2015    1 day ago   \n",
       "18   Does anyone have experience with the Up Mocc ...  Jan 2013  Jun 17 2020   \n",
       "19   I got them because the mocs aren't what they ...  Jun 2013  Jun 17 2020   \n",
       "\n",
       "    num_likes  \n",
       "0           0  \n",
       "1           1  \n",
       "2           4  \n",
       "3           0  \n",
       "4           0  \n",
       "5           1  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          1  \n",
       "11          0  \n",
       "12          5  \n",
       "13          1  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          1  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the page_num column\n",
    "\n",
    "for i in range(len(df[\"page_num\"])):\n",
    "    try:\n",
    "        df[\"page_num\"][i] = int(df[\"page_num\"][i])\n",
    "    except:\n",
    "        df[\"page_num\"][i] = 1\n",
    "    if df[\"page_num\"][i] == 0:\n",
    "        df[\"page_num\"][i] = 1\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the post date column\n",
    "date_change_needed = [date for date in df.post_date.unique() if \"ago\" in date]\n",
    "\n",
    "date_dict = {7:\"Jun 29 2020\",\n",
    "            6:\"Jun 30 2020\",\n",
    "            5:\"Jul 1 2020\",\n",
    "            4:\"Jul 2 2020\",\n",
    "            3:\"Jul 3 2020\",\n",
    "            2:\"Jul 4 2020\",\n",
    "            1: \"Jul 5 2020\"}\n",
    "\n",
    "replacement_dates = dict()\n",
    "for date in date_change_needed:\n",
    "    if \"hour\" in date:\n",
    "        replacement_dates[date] = \"Jul 6 2020\"\n",
    "        continue\n",
    "    if \"min\" in date:\n",
    "        replacement_dates[date] = \"Jul 6 2020\"\n",
    "        continue\n",
    "    if \"7\" in date:\n",
    "        replacement_dates[date] = date_dict[7]\n",
    "    if \"6\" in date:\n",
    "        replacement_dates[date] = date_dict[6]\n",
    "    if \"5\" in date:\n",
    "        replacement_dates[date] = date_dict[5]\n",
    "    if \"4\" in date:\n",
    "        replacement_dates[date] = date_dict[4]\n",
    "    if \"3\" in date:\n",
    "        replacement_dates[date] = date_dict[3]\n",
    "    if \"2\" in date:\n",
    "        replacement_dates[date] = date_dict[2]\n",
    "    if \"1\" in date:\n",
    "        replacement_dates[date] = date_dict[1]\n",
    "\n",
    "for i in range(len(df[\"post_date\"])):\n",
    "    try:\n",
    "        df[\"post_date\"][i] = replacement_dates[df[\"post_date\"][i]]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for date in df.post_date.unique():\n",
    "    if \"19\" not in date:\n",
    "        if \"20\" not in date:\n",
    "            print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciadegner/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Sep 2017', 'May 2006', 'Mar 2019', 'Jun 2015', 'Sep 2010',\n",
       "       'Aug 2011', 'Aug 2013', 'Sep 2016', 'Aug 2008', 'Feb 2020',\n",
       "       'Nov 2015', 'Apr 2015', 'Jan 2013', 'Jun 2013', 'May 2017',\n",
       "       'Jun 2020', 'Apr 2020', 'Dec 2015', 'Jun 2016', 'Jul 2013',\n",
       "       'Dec 2016', 'Nov 2009', 'Oct 2008', 'Sep 2013', 'Oct 2014',\n",
       "       'Aug 2018', 'Jun 2019', 'May 2014', 'Mar 2012', 'Sep 2018',\n",
       "       'Oct 2010', 'Nov 2014', 'Mar 2017', 'Oct 2013', 'Apr 2019',\n",
       "       'Jun 2011', 'Oct 2017', 'Jun 2018', 'Feb 2018', 'Nov 2017',\n",
       "       'May 2020', 'Oct 2015', 'Feb 2012', 'Feb 2010', 'May 2018',\n",
       "       'Mar 2016', 'Apr 2011', 'Mar 2009', 'Mar 2013', 'Aug 2019',\n",
       "       'Feb 2009', 'Aug 2015', 'Feb 2014', 'Feb 2017', 'Oct 2019',\n",
       "       'Jun 2017', 'Mar 2018', 'Sep 2012', 'Jul 2018', 'Aug 2017',\n",
       "       'Aug 2006', 'Feb 2006', 'Jan 2011', 'Jul 2015', 'Jun 2014',\n",
       "       'Jul 2010', 'Oct 2018', 'Mar 2014', 'Feb 2015', 'May 2016',\n",
       "       'Feb 2016', 'Sep 2015', 'May 2011', 'Jan 2016', 'Apr 2004',\n",
       "       'Mar 2002', 'Nov 2012', 'Mar 2020', 'Jun 2009', 'Jan 2001',\n",
       "       'Jan 2007', 'Jul 2014', 'Apr 2012', 'Mar 2006', 'Dec 2014',\n",
       "       'Dec 2010', 'Nov 2018', 'May 2015', 'Apr 2010', 'Sep 2005',\n",
       "       'Apr 2018', 'Aug 2012', 'Dec 2004', 'Apr 2017', 'Dec 2013',\n",
       "       'Jan 2019', 'Dec 2017', 'Oct 2016', 'Nov 2007', 'Oct 2009',\n",
       "       'Jul 2016', 'Jun 2010', 'Nov 2010', 'Dec 2012', 'Nov 2016',\n",
       "       'Aug 2014', 'Feb 2013', 'Oct 2007', 'Jan 2015', 'Mar 2011',\n",
       "       'Dec 2018', 'Jul 2009', 'Aug 2016', 'Jan 2018', 'Oct 2012',\n",
       "       'Nov 2006', 'Oct 2011', 'Jul 2019', 'Oct 2004', 'Nov 2013',\n",
       "       'Jan 2014', 'Jun 2006', 'Sep 2009', 'Jul 2008', 'Jan 2012',\n",
       "       'Sep 2011', 'Oct 2002', 'Feb 2007', 'Jan 2020', 'Jul 2017',\n",
       "       'Sep 2019', 'Dec 2011', 'Jan 2006', 'Jun 2001', 'unknown',\n",
       "       'Mar 2015', 'Jan 2017', 'Feb 2011', 'Sep 2001', 'Apr 2014',\n",
       "       'May 2007', 'Mar 2007', 'Apr 2016', 'Apr 2002', 'May 2013',\n",
       "       'Dec 2019', 'Jul 2011', 'Sep 2014', 'Jul 2007', 'May 2019',\n",
       "       'Nov 2019', 'Feb 2019', 'Jun 2008', 'Apr 2006', 'Nov 2005',\n",
       "       'Aug 2010', 'Apr 2008', 'Dec 2009', 'Mar 2010', 'Mar 2008',\n",
       "       'Apr 2013', 'May 2010', 'Jul 2012', 'Jul 2005', 'Jun 2007',\n",
       "       'Aug 2007', 'Mar 2004', 'Dec 2006', 'Feb 2008', 'Sep 2007',\n",
       "       'Dec 2008', 'Apr 2009', 'Dec 2002', 'Nov 2011', 'Jul 2006',\n",
       "       'Jan 2010', 'Oct 2005', 'Dec 2003', 'Dec 2007', 'Jan 2009',\n",
       "       'Nov 2003', 'Feb 2004', 'May 2012', 'Jan 2002', 'Jul 2004',\n",
       "       'Aug 2003', 'Apr 2007', 'May 2009', 'Apr 2003', 'Nov 2008',\n",
       "       'Aug 2009', 'Jun 2012', 'Oct 2006', 'Jan 2004', 'May 2003',\n",
       "       'Feb 2003', 'Aug 2004', 'Jul 2003', 'May 2008', 'Aug 2002',\n",
       "       'Jun 2004', 'Jan 2003', 'Sep 2008', 'Jan 2008', 'Sep 2006',\n",
       "       'Nov 2002', 'May 2004', 'Feb 2002', 'Jul 2002', 'Mar 2005',\n",
       "       'Nov 2001', 'Dec 2005', 'Jan 2005', 'May 2002', 'Feb 2005',\n",
       "       'Jun 2002', 'Sep 2002', 'Apr 2001', 'May 2005', 'Jul 2001',\n",
       "       'Dec 2001', 'Aug 2001', 'Sep 2003', 'Oct 2003', 'Mar 2001',\n",
       "       'Aug 2005', 'Nov 2004', 'Mar 2003', 'Jan 2000'], dtype=object)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up join_date column\n",
    "date_change_needed = []\n",
    "for date in df.join_date.unique():\n",
    "    if \"20\" not in date:\n",
    "        if \"19\" not in date:\n",
    "            date_change_needed.append(date)\n",
    "            \n",
    "for i in range(len(df[\"join_date\"])):\n",
    "    if df[\"join_date\"][i] == \"unknown\":\n",
    "        df[\"join_date\"][i] == np.nan\n",
    "        continue\n",
    "    if df[\"join_date\"][i] in date_change_needed:\n",
    "        df[\"join_date\"][i] = \"Jun 2020\"\n",
    "df.join_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/patriciadegner/Documents/MIDS/DL/final_project/review_forum.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
